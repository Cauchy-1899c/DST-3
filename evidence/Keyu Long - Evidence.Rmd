---
title: "GBM"
author: "Keyu Long"
date: "11/18/2019"
output: html_document
---
First of all, library the package we need.
```{r}
library(data.table)
library(dplyr)
library(stats)
library(ggplot2)
library(tidyverse)
require(purrr)
require(readr)
library(DataExplorer)
require(scales)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(corrplot)
library(caret)
library(gbm)
```

load the data
```{r}
# kddata=fread("/Users/longkeyu/Desktop/Bristol/DataScienceToolbox/kddcup/kddcup.data_10_percent")
# #read the name of the data
# kddnames=read.table("/Users/longkeyu/Desktop/Bristol/DataScienceToolbox/kddcup/kddcup.names",sep=":",skip=1,as.is=T)
# #give every column name 
# colnames(kddata)=c(kddnames[,1],"normal")
```

```{R}
#choose only 10% data
#kddata=lapply(kddata,function(x){
#  if(length(x)<0.1*length(x)) return(x)
#  return(sample(x,size = 0.1*length(x)))
#})
#kddata=as.data.frame(kddata) #transfer the data into dataframe
#kddata=kddata %>% mutate(id=row_number()) #give every row the id so we can use id to seperate the train set and test set
```



```{r}
#check the normal type
# table(kddata$normal)
```

```{R}
# #put the name of column normal into stab
# stab <- table(kddata$normal)
# #translate any normal type with frequency < 4000 into "other"
# kddata[kddata$normal %in% names(stab[stab<4000]), "normal"] <- "other"
# #check the normal type again
# table(kddata$normal)
```

```{R}
#check the service types 
# table(kddata$service)
```

```{R}
# #put the name of column service into stab2
# stab1 <- table(kddata$service)
# #translate any service type with frequency < 4000 into "other"
# kddata[kddata$service %in% names(stab1[stab1<4000]),"service"] <- "other"
# #check the service type again
# table(kddata$service)
```

Load the data that has been processed.
```{R}
kddata_bin_DV <- fread("/Users/longkeyu/Desktop/Bristol/DataScienceToolbox/assessment3/dstdata.csv")

#kddata=kddata %>% mutate(id=row_number()) 
```

```{R}
# stab2=names(kddata)#put the column name of the kddata into stab2
# 
# #using for loop to make every character-class column become factor-class
# #for(i in 1:ncol(kddata)){
# #  if(class(kddata[,stab2[i]])=="character"){
# #    kddata[,stab2[i]]=as.factor(kddata[,stab2[i]])
# #  }
# #}
# 
# #putting kddata in to kdd_bin_DV
# kdd_bin_DV <- kddata
# 
# 
# # Filter out all factor variables
# facots <- names(kdd_bin_DV)[sapply(kdd_bin_DV, class) == 'character'] 
# facots=facots[-4]
# 
# #Convert factor variable to the right half of formula
# formula <- as.formula(paste('~', paste(facots, collapse = '+')))
# 
# #getting dummy variable
# dummy <- dummyVars(formula = formula, data = kdd_bin_DV)
# pred <- data.frame(predict(dummy, newdata = kdd_bin_DV))#actually I don't know what is going on in this line...
# 
# #add other column which class is not "factor"
# kdd_bin_DV <- cbind(kdd_bin_DV[,c(5:11,42)],pred)

```


```{r}
#将normal和非normal作类型转换，1为normal，0为unnormal
#data[,"normal"]=ifelse(data[,"normal"]=="normal.",1,0)
#sort(table(data$normal))
#data=data[,5:42]
```


```{R}
# kddata_bin_DV <- scale(kdd_bin_DV[,-8])
# 
# kddata_bin_DV <- as.data.frame(kddata_bin_DV)
# 
# kddata_bin_DV <- kddata_bin_DV %>% mutate(normal=kddata$normal)
```

```{R}
# for(i in nrow(kddata_bin_DV)){
#   if(kddata_bin_DV$normal[i]=="normal."){
#     kddata_bin_DV$normal[i]="Seg1"
#   }
#   if(kddata_bin_DV$normal[i]=="smurf."){
#     kddata_bin_DV$normal[i]="Seg2"
#   }
#   if(kddata_bin_DV$normal[i]=="neptune."){
#     kddata_bin_DV$normal[i]="Seg3"
#   }
#   else{
#     kddata_bin_DV$normal[i]="Seg4"
#   }
# }
```


divide the dataset into train set and test set.
```{r}
#set.seed(1)
#give dataset the row number in order to seperate
kddata_bin_DV <- kddata_bin_DV %>% mutate(id=row_number())

data_train <-  kddata_bin_DV %>% sample_frac(.70) #the percentage of the train set

data_test=anti_join(kddata_bin_DV, data_train, by = 'id') #rest of the data mades the test set 

data_train=data_train[,-length(data_train)]#delete the id

data_test=data_test[,-length(data_test)]#delete the id
```



```{R}
#fitControl <- trainControl(method="repeatedcv",
#                           number=4,
#                           repeats=1,
#                           verboseIter=TRUE)
#set.seed(825)
#gbmFit <- train(normal ~ ., data=data_train,
#                method="gbm",
#                trControl=fitControl,
#                verbose=TRUE)
```


delete the factor that will influence the result
```{R}
#delete the factor influence normal
data_train_normal=data_train[,-c(30,32,33)]
data_test_normal=data_test[,-c(30,32,33)]

#delete the factor influence neptune
data_train_neptune=data_train[,-(31:33)]
data_test_neptune=data_test[,-(31:33)]

#delete the factor influence smurf
data_train_smurf=data_train[,-(30:32)]
data_test_smurf=data_test[,-(30:32)]

#delete the factor influence other
data_train_other=data_train[,-c(30,31,33)]
data_test_other=data_test[,-c(30,31,33)]
```


train the data and print the model object,then summary it to see the result
```{R}
# Train a 10000-tree GBM model
set.seed(1)
#using gbm to train result about normal
data_model_normal <- gbm(formula = normalnormal. ~ ., 
                    data = data_train_normal,
                    n.trees = 1000,
                    distribution="bernoulli",
                  verbose=FALSE)

#using gbm to train result about neptune
data_model_neptune <- gbm(formula = normalneptune. ~ ., 
                    data = data_train_neptune,
                    n.trees = 1000,
                    distribution="bernoulli",
                  verbose=FALSE)

#using gbm to train result about smurf
data_model_smurf <- gbm(formula = normalsmurf. ~ ., 
                    data = data_train_smurf,
                    n.trees = 1000,
                    distribution="bernoulli",
                  verbose=FALSE)

#using gbm to train result about other
data_model_other <- gbm(formula = normalother ~ ., 
                    data = data_train_other,
                    n.trees = 1000,
                    distribution="bernoulli",
                  verbose=FALSE)

# Print the model object                    
print(data_model_normal) #normal
print(data_model_neptune) #neptune
print(data_model_smurf) #smurf
print(data_model_other) #other

# summary() prints variable importance
summary(data_model_normal) #normal
summary(data_model_neptune) #neptune
summary(data_model_smurf) #smurf
summary(data_model_other) #other
```
From the above graph, we can see the relative influence of the features to the graph.
count,src_bytes and logged_in influence the normal part most.
src_bytes,service of private and flag of SF influence of neptune part most.
srv_count, service of ecr_i, src_bytes and count influence of the smurf part most.
src_bytes, service of other and flag of RSTR influence of the other part most.





Prediction using a GBM model
```{R}
# Generate predictions of normal on the test set
preds_normal <- predict(object = data_model_normal, 
                  newdata = data_test,
                  n.trees = 1000)

# Generate predictions of neptune on the test set
preds_neptune <- predict(object = data_model_neptune, 
                  newdata = data_test,
                  n.trees = 1000)

# Generate predictions of smurf on the test set
preds_smurf <- predict(object = data_model_smurf, 
                  newdata = data_test,
                  n.trees = 1000)

# Generate predictions of other on the test set
preds_other <- predict(object = data_model_other, 
                  newdata = data_test,
                  n.trees = 1000)

# Compare the range of the four sets of predictions
range(preds_normal) #normal
range(preds_neptune) #neptune
range(preds_smurf) #smurf
range(preds_other) #other
```
the mean ,variance

Evaluate test set AUC,I feel suprised about the result. As I know, gbm will perform bad if we do not tune it.But the result shows that the accuracy is pretty good. 
```{R}
#in order to calculate auc
library(Metrics)

auc(actual = data_test_normal$normalnormal., predicted = preds_normal)#normal 
auc(actual = data_test_neptune$normalneptune., predicted = preds_neptune) #neptune 
auc(actual = data_test_smurf$normalsmurf., predicted = preds_smurf) #smurf
auc(actual = data_test_other$normalother, predicted = preds_other) #other
```


Early stopping in GBMs(May spend several minutes to run this chunk)
```{R}
# Optimal ntree estimate about normal feature based on OOB
ntree_opt_oob_normal <- gbm.perf(object = data_model_normal, 
                          method = "OOB", 
                          oobag.curve = TRUE)

# Optimal ntree estimate about neptune feature based on OOB
ntree_opt_oob_neptune <- gbm.perf(object = data_model_neptune, 
                          method = "OOB", 
                          oobag.curve = TRUE)

# Optimal ntree estimate about smurf feature based on OOB
ntree_opt_oob_smurf <- gbm.perf(object = data_model_smurf, 
                          method = "OOB", 
                          oobag.curve = TRUE)

# Optimal ntree estimate about other feature based on OOB
ntree_opt_oob_other <- gbm.perf(object = data_model_other, 
                          method = "OOB", 
                          oobag.curve = TRUE)


# Train a Cross Validation of normal feature GBM model
set.seed(1)
data_model_cv_normal <- gbm(formula = normalnormal. ~ ., 
                       distribution = "bernoulli", 
                       data = data_train_normal,
                       n.trees = 1000,
                       cv.folds = 2)

# Train a Cross Validation of neptune feature GBM model
data_model_cv_neptune <- gbm(formula = normalneptune. ~ ., 
                       distribution = "bernoulli", 
                       data = data_train_neptune,
                       n.trees = 1000,
                       cv.folds = 2)

# Train a Cross Validation of smurf feature GBM model
data_model_cv_smurf <- gbm(formula = normalsmurf. ~ ., 
                       distribution = "bernoulli", 
                       data = data_train_smurf,
                       n.trees = 1000,
                       cv.folds = 2)

# Train a Cross Validation of other feature GBM model
data_model_cv_other <- gbm(formula = normalother ~ ., 
                       distribution = "bernoulli", 
                       data = data_train_other,
                       n.trees = 1000,
                       cv.folds = 2)
                       
# Optimal ntree estimate of noraml based on CV
ntree_opt_cv_normal <- gbm.perf(object = data_model_cv_normal, 
                         method = "cv")
 
# Optimal ntree estimate of neptune based on CV                        
ntree_opt_cv_neptune <- gbm.perf(object = data_model_cv_neptune, 
                         method = "cv")

# Optimal ntree estimate of smurf based on CV
ntree_opt_cv_smurf <- gbm.perf(object = data_model_cv_smurf, 
                         method = "cv")

# Optimal ntree estimate of other based on CV
ntree_opt_cv_other <- gbm.perf(object = data_model_cv_other, 
                         method = "cv")

# Compare the estimates                         
print(paste0("Optimal n.trees (OOB Estimate): ", ntree_opt_oob_normal))                         
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv_normal))

print(paste0("Optimal n.trees (OOB Estimate): ", ntree_opt_oob_smurf))                         
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv_smurf))

print(paste0("Optimal n.trees (OOB Estimate): ", ntree_opt_oob_neptune))                         
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv_neptune))

print(paste0("Optimal n.trees (OOB Estimate): ", ntree_opt_oob_other))                         
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv_other))
```

OOB vs CV-based early stopping
```{R}
library(ROCR)
# Generate predictions on the test set of normal using ntree_opt_oob number of trees
preds_oob_normal <- predict(object = data_model_normal, 
                  newdata = data_test_normal,
                  n.trees = ntree_opt_oob_normal)

# Generate predictions on the test set of neptune using ntree_opt_oob number of trees
preds_oob_neptune <- predict(object = data_model_neptune, 
                  newdata = data_test_neptune,
                  n.trees = ntree_opt_oob_neptune)

# Generate predictions on the test set of smurf using ntree_opt_oob number of trees
preds_oob_smurf <- predict(object = data_model_smurf, 
                  newdata = data_test_smurf,
                  n.trees = ntree_opt_oob_smurf)

# Generate predictions on the test set of other using ntree_opt_oob number of trees
preds_oob_other <- predict(object = data_model_other, 
                  newdata = data_test_other,
                  n.trees = ntree_opt_oob_other)

# Generate predictions on the test set of normal feature using ntree_opt_cv number of trees
preds_cv_normal <- predict(object = data_model_normal, 
                  newdata = data_test_normal,
                  n.trees = ntree_opt_cv_normal)   

# Generate predictions on the test set of neptune feature using ntree_opt_cv number of trees
preds_cv_neptune <- predict(object = data_model_neptune, 
                  newdata = data_test_neptune,
                  n.trees = ntree_opt_cv_neptune)   

# Generate predictions on the test set of smurf feature using ntree_opt_cv number of trees
preds_cv_smurf <- predict(object = data_model_smurf, 
                  newdata = data_test_smurf,
                  n.trees = ntree_opt_cv_smurf)   

# Generate predictions on the test set of other feature using ntree_opt_cv number of trees
preds_cv_other <- predict(object = data_model_other, 
                  newdata = data_test_other,
                  n.trees = ntree_opt_cv_other)   


# Generate the test set AUCs using the two sets of preditions & compare
auc_oob_normal <- auc(actual = data_test_normal$normalnormal., predicted = preds_oob_normal)  #OOB
auc_cv_normal <- auc(actual = data_test_normal$normalnormal., predicted = preds_cv_normal)  #CV 

auc_oob_neptune <- auc(actual = data_test_neptune$normalneptune., predicted = preds_oob_neptune)  #OOB
auc_cv_neptune <- auc(actual = data_test_neptune$normalneptune., predicted = preds_cv_neptune)  #CV 

auc_oob_smurf <- auc(actual = data_test_smurf$normalsmurf., predicted = preds_oob_smurf)  #OOB
auc_cv_smurf <- auc(actual = data_test_smurf$normalsmurf., predicted = preds_cv_smurf)  #CV 

auc_oob_other <- auc(actual = data_test_other$normalother, predicted = preds_oob_other)  #OOB
auc_cv_other <- auc(actual = data_test_other$normalother, predicted = preds_cv_other)  #CV 

# Compare AUC 
#normal
print(paste0("Test set AUC (OOB): ", auc_oob_normal))                         
print(paste0("Test set AUC (CV): ", auc_cv_normal))

#neptune
print(paste0("Test set AUC (OOB): ", auc_oob_neptune))                         
print(paste0("Test set AUC (CV): ", auc_cv_neptune))

#smurf
print(paste0("Test set AUC (OOB): ", auc_oob_smurf))                         
print(paste0("Test set AUC (CV): ", auc_cv_smurf))

#other
print(paste0("Test set AUC (OOB): ", auc_oob_other))                         
print(paste0("Test set AUC (CV): ", auc_cv_other))
```

check the result
```{R}
actual_normal = data_test_normal$normalnormal. #actual value
#predict
gbm_preds_normal <- predict(object = data_model_normal, 
                  newdata = data_test_normal,
                  n.trees = ntree_opt_cv_normal)

gbm_auc_normal <- auc(actual = actual_normal, predicted = gbm_preds_normal) #normal



actual_neptune = data_test_neptune$normalneptune. #actual value
#predict
gbm_preds_neptune <- predict(object = data_model_neptune, 
                  newdata = data_test_neptune,
                  n.trees = ntree_opt_cv_neptune)

gbm_auc_neptune <- auc(actual = actual_neptune, predicted = gbm_preds_neptune) #neptune


actual_smurf = data_test_smurf$normalsmurf. #actual value
#predict
gbm_preds_smurf <- predict(object = data_model_smurf, 
                  newdata = data_test_smurf,
                  n.trees = ntree_opt_cv_smurf)

gbm_auc_smurf <- auc(actual = actual_smurf, predicted = gbm_preds_smurf) #smurf


actual_other = data_test_other$normalother #actual value
#predict
gbm_preds_other <- predict(object = data_model_other, 
                  newdata = data_test_other,
                  n.trees = ntree_opt_cv_other)

gbm_auc_other <- auc(actual = actual_other, predicted = gbm_preds_other) #other

#print the result
gbm_auc_normal
gbm_auc_neptune
gbm_auc_smurf
gbm_auc_other


# # List of predictions
# preds_list_normal <- list(gbm_preds)
# 
# # List of actual values (same for all)
# m_normal <- length(preds_list)
# actuals_list_normal <- rep(list(data_test_normal$normalnormal.), m)

# Plot the ROC curves
# pred_normal <- prediction(preds_list_normal, actuals_list_normal)
# rocs_normal <- performance(pred_normal, "tpr", "fpr")
# plot(rocs, col = as.list(1:m), main = "Test Set ROC Curves")
# legend(x = "bottomright", 
#        legend = c("GBM"),
#        fill = 1:m)

```

In order to show the total accuracy, we should first change the form into binary structure.
```{R}
#transfer the form of neptune into binary in order to calculate the total variance
for(i in 1:length(gbm_preds_neptune)){
  gbm_preds_neptune[i] <- ifelse(gbm_preds_neptune[i]<=0.5,0,1)
}
#transfer the form of normal into binary in order to calculate the total variance
for(i in 1:length(gbm_preds_normal)){
  gbm_preds_normal[i] <- ifelse(gbm_preds_normal[i]<=0.5,0,1)
}
#transfer the form of smurf into binary in order to calculate the total variance
for(i in 1:length(gbm_preds_smurf)){
  gbm_preds_smurf[i] <- ifelse(gbm_preds_smurf[i]<=0.5,0,1)
}
#transfer the form of other into binary in order to calculate the total variance
for(i in 1:length(gbm_preds_other)){
  gbm_preds_other[i] <- ifelse(gbm_preds_other[i]<=0.5,0,1)
}
```


every accuracy part. 
```{R}
#accuracy of normal
table_mat_normal = table(data_test_normal$normalnormal., gbm_preds_normal)
accuracy_Test_normal = sum(diag(table_mat_normal)) / sum(table_mat_normal)
accuracy_Test_normal

#accuracy of neptune 
table_mat_neptune = table(data_test_neptune$normalneptune., gbm_preds_neptune)
accuracy_Test_neptune = sum(diag(table_mat_neptune)) / sum(table_mat_neptune)
accuracy_Test_neptune

#accuracy of smurf
table_mat_smurf = table(data_test_smurf$normalsmurf., gbm_preds_smurf)
accuracy_Test_smurf = sum(diag(table_mat_smurf)) / sum(table_mat_smurf)
accuracy_Test_smurf

#accuracy of other
table_mat_other = table(data_test_other$normalother, gbm_preds_other)
accuracy_Test_other = sum(diag(table_mat_other)) / sum(table_mat_other)
accuracy_Test_other
```

calculate the total accuracy.
```{R}
#calculate the total accuracy
total_accuracy=(sum(diag(table_mat_normal))+sum(diag(table_mat_neptune))+sum(diag(table_mat_smurf))+sum(diag(table_mat_other)))/(sum(table_mat_other)+sum(table_mat_neptune)+sum(table_mat_normal)+sum(table_mat_smurf))
#show the result
total_accuracy
```
```{R}
gbm_preds_normal=as.factor(gbm_preds_normal) #transfer data into factor
gbm_preds_neptune=as.factor(gbm_preds_neptune) #transfer data into factor
gbm_preds_smurf=as.factor(gbm_preds_smurf) #transfer data into factor
gbm_preds_other=as.factor(gbm_preds_other) #transfer data into factor

a_normal=as.factor(actual_normal) #transfer data into factor
a_neptune=as.factor(actual_neptune) #transfer data into factor
a_smurf=as.factor(actual_smurf) #transfer data into factor
a_other=as.factor(actual_other) #transfer data into factor
```

```{R}
CM_normal <- confusionMatrix(gbm_preds_normal,a_normal) #calculate the confusion matrex
CM_neptune <- confusionMatrix(gbm_preds_neptune,a_neptune) #calculate the confusion matrex
CM_smurf <- confusionMatrix(gbm_preds_smurf,a_smurf) #calculate the confusion matrex
CM_other <- confusionMatrix(gbm_preds_other,a_other) #calculate the confusion matrex
```

confusion matrix.
```{R}
#put four vectors of prediction into gbm_preds_total 
gbm_preds_total <- rbind(gbm_preds_normal,gbm_preds_neptune,gbm_preds_smurf,gbm_preds_other)
#transfer this vector into factor
gbm_preds_total <- as.factor(gbm_preds_total)
#put four vectors of actual data into actual_total
actual_total <- rbind(a_normal,a_neptune,a_smurf,a_other)
#transfer this vector into factor
a_total <- as.factor(actual_total)
#calculate the confusion matrix
confusionMatrix(gbm_preds_total,a_total)
```

```{R}
a=cbind(gbm_preds_normal,gbm_preds_neptune,gbm_preds_smurf,gbm_preds_other)
a=a-1
b=cbind(actual_normal,actual_neptune,actual_smurf,actual_other)
a=as.data.frame(a)
b=as.data.frame(b)

transfer=function(x){
  v=rep(0,dim(x)[1])
  for(i in 1:dim(x)[1]){
    if(x[i,1]==1){
      v[i]="normal"
    }
    else if(x[i,2]==1){
      v[i]="neptune"
    }
    else if(x[i,3]==1){
      v[i]="smurf"
    }
    else{
      v[i]="other"
    }
  }
  v
}
```

```{R}
#transfer the dummy variable into the actual variable
transfered_pred <- transfer(a)
transfered_actual <- transfer(b)

#transfer that form of actual variable into factors
transfered_actual <- as.factor(transfered_actual)
transfered_pred <- as.factor(transfered_pred)
```


```{R}
#transfered confusioin Matrix
confusionMatrix(transfered_actual,transfered_pred)
```
